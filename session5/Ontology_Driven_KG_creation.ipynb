{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbarrasa/goingmeta/blob/main/session5/Ontology_Driven_KG_creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {
        "id": "uhuV0UJzbekv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rdflib in c:\\users\\britt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (7.0.0)Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.1.1 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Requirement already satisfied: neo4j in c:\\users\\britt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (5.24.0)\n",
            "Requirement already satisfied: pandas in c:\\users\\britt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.2.3)\n",
            "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in c:\\users\\britt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rdflib) (0.6.1)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\britt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rdflib) (3.1.4)\n",
            "Requirement already satisfied: pytz in c:\\users\\britt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from neo4j) (2024.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\britt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\britt\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\britt\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six in c:\\users\\britt\\appdata\\roaming\\python\\python39\\site-packages (from isodate<0.7.0,>=0.6.0->rdflib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install rdflib neo4j pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {
        "id": "qf3yMwgyVg05"
      },
      "outputs": [],
      "source": [
        "import rdflib, time\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "\n",
        "from neo4j import GraphDatabase, basic_auth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Britt settings:\n",
            "S:\\Users\\Britt\\Documents\\Visual_Studio_GitHub\\Visual_Studio_Code_Python\\GoingMeta\\session5\\data\n",
            "S:/Users/Britt/Documents/Visual_Studio_GitHub/Visual_Studio_Code_Python/GoingMeta/session5/ontos/rail.ttl\n"
          ]
        }
      ],
      "source": [
        "print(\"Britt settings:\")\n",
        "data_dir=\"https://raw.githubusercontent.com/jbarrasa/goingmeta/main/session5/data/\"\n",
        "data_dir=r\"S:\\Users\\Britt\\Documents\\Visual_Studio_GitHub\\Visual_Studio_Code_Python\\GoingMeta\\session5\\data\" + r\"\\\\\"\n",
        "#print(data_dir)\n",
        "print(pathlib.Path(data_dir))\n",
        "\n",
        "onto = \"https://raw.githubusercontent.com/jbarrasa/goingmeta/main/session5/ontos/rail.ttl\"\n",
        "onto = \"S:/Users/Britt/Documents/Visual_Studio_GitHub/Visual_Studio_Code_Python/GoingMeta/session5/ontos/rail.ttl\"\n",
        "print(onto)\n",
        "\n",
        "import_csv_file=r\"S:\\Users\\Britt\\Documents\\Visual_Studio_GitHub\\Visual_Studio_Code_Python\\GoingMeta\\session5\\data\" + r\"\\\\\" + r\"new_links.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {
        "id": "eRYK8Uvk67jQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verify rdf ontology functions getLocalPart and getNamespacePart\n",
            "Station\n",
            "http://onto.neo4j.com/rail#\n"
          ]
        }
      ],
      "source": [
        "#utility function to get the local part of a URI (stripping out the namespace)\n",
        "print(\"Verify rdf ontology functions getLocalPart and getNamespacePart\")\n",
        "\n",
        "def getLocalPart(uri):\n",
        "  pos = -1\n",
        "  pos = uri.rfind('#') \n",
        "  if pos < 0 :\n",
        "    pos = uri.rfind('/')  \n",
        "  if pos < 0 :\n",
        "    pos = uri.rindex(':')\n",
        "  return uri[pos+1:]\n",
        "\n",
        "def getNamespacePart(uri):\n",
        "  pos = -1\n",
        "  pos = uri.rfind('#') \n",
        "  if pos < 0 :\n",
        "    pos = uri.rfind('/')  \n",
        "  if pos < 0 :\n",
        "    pos = uri.rindex(':')\n",
        "  return uri[0:pos+1]\n",
        "\n",
        "# quick test\n",
        "print(getLocalPart(\"http://onto.neo4j.com/rail#Station\"))\n",
        "print(getNamespacePart(\"http://onto.neo4j.com/rail#Station\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {
        "id": "I_oshqtSP_fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create graph from rdf ontology\n",
            "S:/Users/Britt/Documents/Visual_Studio_GitHub/Visual_Studio_Code_Python/GoingMeta/session5/ontos/rail.ttl\n",
            "\n",
            "Query graph for all owl:Class\n",
            "http://onto.neo4j.com/rail#Event Event http://onto.neo4j.com/rail#\n",
            "http://onto.neo4j.com/rail#Station Station http://onto.neo4j.com/rail#\n",
            "\n",
            "Query graph for all owl:ObjectProperty\n",
            "http://onto.neo4j.com/rail#affects affects http://onto.neo4j.com/rail#\n",
            "http://onto.neo4j.com/rail#link link http://onto.neo4j.com/rail#\n"
          ]
        }
      ],
      "source": [
        "# processing the ontology...\n",
        "print(\"Create graph from rdf ontology\")\n",
        "print(onto)\n",
        "\n",
        "graph_onto = rdflib.Graph()\n",
        "graph_onto.parse(onto, format='turtle')\n",
        "\n",
        "graph_query_classes = \"\"\"\n",
        "prefix owl: <http://www.w3.org/2002/07/owl#> \n",
        "prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
        "SELECT DISTINCT ?c\n",
        "  WHERE {\n",
        "    ?c rdf:type owl:Class .    \n",
        "  } \"\"\"\n",
        "print(\"\\nQuery graph for all owl:Class\")\n",
        "for row in graph_onto.query(graph_query_classes):\n",
        "    print(str(row.c), getLocalPart(str(row.c)), getNamespacePart(str(row.c)))\n",
        "\n",
        "graph_query_properties = \"\"\"\n",
        "prefix owl: <http://www.w3.org/2002/07/owl#> \n",
        "prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
        "SELECT DISTINCT ?c\n",
        "  WHERE {\n",
        "    ?c rdf:type owl:ObjectProperty .    \n",
        "  } \"\"\"\n",
        "print(\"\\nQuery graph for all owl:ObjectProperty\")\n",
        "for row in graph_onto.query(graph_query_properties):\n",
        "    print(str(row.c), getLocalPart(str(row.c)), getNamespacePart(str(row.c)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {
        "id": "5jtsSEJnbtVq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generate cypher query from ontology (without mappings)\n",
            "\n",
            "List of generated cypher queries\n",
            "\n",
            "unwind $records AS record \n",
            "merge (n:Event { `<id_prop>`: record.`<col with id>`} ) \n",
            "set n.eventDescription = record.`<col with value for eventDescription>` \n",
            "set n.eventId = record.`<col with value for eventId>` \n",
            "set n.eventType = record.`<col with value for eventType>` \n",
            "return count(*) as total\n",
            "\n",
            "unwind $records AS record \n",
            "merge (n:Station { `<id_prop>`: record.`<col with id>`} ) \n",
            "set n.lat = record.`<col with value for lat>` \n",
            "set n.long = record.`<col with value for long>` \n",
            "set n.stationAddress = record.`<col with value for stationAddress>` \n",
            "set n.stationCode = record.`<col with value for stationCode>` \n",
            "set n.stationName = record.`<col with value for stationName>` \n",
            "return count(*) as total\n",
            "\n",
            "unwind $records AS record \n",
            "match (source:Event { `<id_prop>`: record.`<col with source id>`} ) \n",
            "match (target:Station { `<id_prop>`: record.`<col with target id>`} ) \n",
            "merge (source)-[r:`affects`]->(target) \n",
            "return count(*) as total\n",
            "\n",
            "unwind $records AS record \n",
            "match (source:Station { `<id_prop>`: record.`<col with source id>`} ) \n",
            "match (target:Station { `<id_prop>`: record.`<col with target id>`} ) \n",
            "merge (source)-[r:`link`]->(target) \n",
            "return count(*) as total\n"
          ]
        }
      ],
      "source": [
        "# read the onto and generate cypher (complete without mappings)\n",
        "print(\"Generate cypher query from ontology (without mappings)\")\n",
        "\n",
        "classes_and_props_query = \"\"\"\n",
        "prefix owl: <http://www.w3.org/2002/07/owl#> \n",
        "prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
        "\n",
        "SELECT DISTINCT ?curi (GROUP_CONCAT(DISTINCT ?propTypePair ; SEPARATOR=\",\") AS ?props)\n",
        "WHERE {\n",
        "    ?curi rdf:type owl:Class .\n",
        "    optional { \n",
        "      ?prop rdfs:domain ?curi ;\n",
        "        a owl:DatatypeProperty ;\n",
        "        rdfs:range ?range .\n",
        "      BIND (concat(str(?prop),';',str(?range)) AS ?propTypePair)\n",
        "    }\n",
        "  } GROUP BY ?curi  \"\"\"\n",
        "\n",
        "cypher_list = []\n",
        "\n",
        "for row in graph_onto.query(classes_and_props_query):\n",
        "    cypher = []\n",
        "    cypher.append(\"unwind $records AS record\")\n",
        "    cypher.append(\"merge (n:\" + getLocalPart(row.curi) + \" { `<id_prop>`: record.`<col with id>`} )\")\n",
        "    for pair in row.props.split(\",\"):\n",
        "      propName = pair.split(\";\")[0]\n",
        "      propType = pair.split(\";\")[1]\n",
        "      cypher.append(\"set n.\" + getLocalPart(propName) + \" = record.`<col with value for \" + getLocalPart(propName) + \">`\")\n",
        "    cypher.append(\"return count(*) as total\") \n",
        "    cypher_list.append(' \\n'.join(cypher))\n",
        "\n",
        "\n",
        "rels_query = \"\"\"\n",
        "prefix owl: <http://www.w3.org/2002/07/owl#> \n",
        "prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
        "\n",
        "SELECT DISTINCT ?rel ?dom ?ran #(GROUP_CONCAT(DISTINCT ?relTriplet ; SEPARATOR=\",\") AS ?rels)\n",
        "WHERE {\n",
        "    ?rel a ?propertyClass .\n",
        "    filter(?propertyClass in (rdf:Property, owl:ObjectProperty, owl:FunctionalProperty, owl:AsymmetricProperty, \n",
        "           owl:InverseFunctionalProperty, owl:IrreflexiveProperty, owl:ReflexiveProperty, owl:SymmetricProperty, owl:TransitiveProperty))\n",
        "    \n",
        "    ?rel rdfs:domain ?dom ;\n",
        "      rdfs:range ?ran .\n",
        "    \n",
        "    #BIND (concat(str(?rel),';',str(?dom),';',str(?range)) AS ?relTriplet)\n",
        "    \n",
        "  }\"\"\"\n",
        "\n",
        "\n",
        "for row in graph_onto.query(rels_query):\n",
        "  cypher = []\n",
        "  cypher.append(\"unwind $records AS record\")\n",
        "  cypher.append(\"match (source:\" + getLocalPart(row.dom) + \" { `<id_prop>`: record.`<col with source id>`} )\")\n",
        "  cypher.append(\"match (target:\" + getLocalPart(row.ran) + \" { `<id_prop>`: record.`<col with target id>`} )\")\n",
        "  cypher.append(\"merge (source)-[r:`\"+ getLocalPart(row.rel) +\"`]->(target)\")\n",
        "  cypher.append(\"return count(*) as total\") \n",
        "  cypher_list.append(' \\n'.join(cypher))\n",
        "\n",
        "print(\"\\nList of generated cypher queries\")\n",
        "for q in cypher_list:\n",
        "  print(\"\\n\" + q)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {
        "id": "F4GP70jAf8v2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Define mappings: rail, station, event, link, affects\n",
            "S:\\Users\\Britt\\Documents\\Visual_Studio_GitHub\\Visual_Studio_Code_Python\\GoingMeta\\session5\\data\\nr-stations-all.csv\n",
            "\n",
            "Example mappings: railMappings\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'Station': {'@fileName': 'S:\\\\Users\\\\Britt\\\\Documents\\\\Visual_Studio_GitHub\\\\Visual_Studio_Code_Python\\\\GoingMeta\\\\session5\\\\data\\\\\\\\nr-stations-all.csv',\n",
              "  '@uniqueId': 'stationCode',\n",
              "  'lat': 'lat',\n",
              "  'long': 'long',\n",
              "  'stationAddress': 'address',\n",
              "  'stationCode': 'crs',\n",
              "  'stationName': 'name'},\n",
              " 'Event': {'@fileName': 'S:\\\\Users\\\\Britt\\\\Documents\\\\Visual_Studio_GitHub\\\\Visual_Studio_Code_Python\\\\GoingMeta\\\\session5\\\\data\\\\\\\\nr-events.csv',\n",
              "  '@uniqueId': 'eventId',\n",
              "  'eventDescription': 'desc',\n",
              "  'eventId': 'id',\n",
              "  'timestamp': 'ts',\n",
              "  'eventType': 'type'},\n",
              " 'link': {'@fileName': 'S:\\\\Users\\\\Britt\\\\Documents\\\\Visual_Studio_GitHub\\\\Visual_Studio_Code_Python\\\\GoingMeta\\\\session5\\\\data\\\\\\\\nr-station-links.csv',\n",
              "  '@from': 'origin',\n",
              "  '@to': 'destination'},\n",
              " 'affects': {'@fileName': 'S:\\\\Users\\\\Britt\\\\Documents\\\\Visual_Studio_GitHub\\\\Visual_Studio_Code_Python\\\\GoingMeta\\\\session5\\\\data\\\\\\\\nr-events.csv',\n",
              "  '@from': 'id',\n",
              "  '@to': 'Station'}}"
            ]
          },
          "execution_count": 317,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Define mappings: rail, station, event, link, affects\")\n",
        "\n",
        "railMappings = {}\n",
        "stationMapping = {}\n",
        "eventMapping = {}\n",
        "linkMapping = {}\n",
        "affectsMapping = {}\n",
        "\n",
        "print(pathlib.Path(data_dir + \"nr-stations-all.csv\"))\n",
        "\n",
        "stationMapping[\"@fileName\"] = data_dir + \"nr-stations-all.csv\"\n",
        "stationMapping[\"@uniqueId\"] = \"stationCode\"\n",
        "stationMapping[\"lat\"] = \"lat\"\n",
        "stationMapping[\"long\"] = \"long\"\n",
        "stationMapping[\"stationAddress\"] = \"address\"\n",
        "stationMapping[\"stationCode\"] = \"crs\"\n",
        "stationMapping[\"stationName\"] = \"name\"\n",
        "railMappings[\"Station\"] = stationMapping\n",
        "\n",
        "eventMapping[\"@fileName\"] = data_dir + \"nr-events.csv\"\n",
        "eventMapping[\"@uniqueId\"] = \"eventId\"\n",
        "eventMapping[\"eventDescription\"] = \"desc\"\n",
        "eventMapping[\"eventId\"] = \"id\"\n",
        "eventMapping[\"timestamp\"] = \"ts\"\n",
        "eventMapping[\"eventType\"] = \"type\"\n",
        "railMappings[\"Event\"] = eventMapping\n",
        "\n",
        "linkMapping[\"@fileName\"] = data_dir + \"nr-station-links.csv\"\n",
        "linkMapping[\"@from\"] = \"origin\"\n",
        "linkMapping[\"@to\"] = \"destination\"\n",
        "railMappings[\"link\"] = linkMapping\n",
        "\n",
        "affectsMapping[\"@fileName\"] = data_dir + \"nr-events.csv\"\n",
        "affectsMapping[\"@from\"] = \"id\"\n",
        "affectsMapping[\"@to\"] = \"Station\"\n",
        "railMappings[\"affects\"] = affectsMapping\n",
        "\n",
        "# show it?\n",
        "print(\"\\nExample mappings: railMappings\")\n",
        "railMappings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {
        "id": "Ouw2B3BmHhn5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Define getLoadersFromOnto to repeat process with mappings\n"
          ]
        }
      ],
      "source": [
        "#copy of previous but using the mappings\n",
        "print(\"Define getLoadersFromOnto to repeat process with mappings\")\n",
        "\n",
        "def getLoadersFromOnto(onto, rdf_format, mappings):\n",
        "  graph_onto_mapped = rdflib.Graph()\n",
        "  graph_onto_mapped.parse(onto, format= rdf_format)\n",
        "\n",
        "  classes_and_props_query = \"\"\"\n",
        "  prefix owl: <http://www.w3.org/2002/07/owl#> \n",
        "  prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
        "\n",
        "  SELECT DISTINCT ?curi (GROUP_CONCAT(DISTINCT ?propTypePair ; SEPARATOR=\",\") AS ?props)\n",
        "  WHERE {\n",
        "      ?curi rdf:type owl:Class .\n",
        "      optional { \n",
        "        ?prop rdfs:domain ?curi ;\n",
        "          a owl:DatatypeProperty ;\n",
        "          rdfs:range ?range .\n",
        "        BIND (concat(str(?prop),';',str(?range)) AS ?propTypePair)\n",
        "      }\n",
        "    } GROUP BY ?curi  \"\"\"\n",
        "\n",
        "  cypher_import = {}\n",
        "  export_ns = set()\n",
        "  export_mappings = {}\n",
        "\n",
        "  for row in graph_onto_mapped.query(classes_and_props_query):\n",
        "      export_ns.add(getNamespacePart(row.curi))\n",
        "      export_mappings[getLocalPart(row.curi)] = str(row.curi)\n",
        "      cypher = []\n",
        "      cypher.append(\"unwind $records AS record\")\n",
        "      cypher.append(\"merge (n:\" + getLocalPart(row.curi) + \" { `\" + mappings[getLocalPart(row.curi)][\"@uniqueId\"] + \"`: record.`\" + mappings[getLocalPart(row.curi)][mappings[getLocalPart(row.curi)][\"@uniqueId\"]] + \"`} )\")\n",
        "      for pair in row.props.split(\",\"):      \n",
        "        propName = pair.split(\";\")[0]\n",
        "        propType = pair.split(\";\")[1]\n",
        "        export_ns.add(getNamespacePart(propName))\n",
        "        export_mappings[getLocalPart(propName)] = propName\n",
        "        #if a mapping (a column in the source file) is defined for the property and property is not a unique id\n",
        "        if getLocalPart(propName) in mappings[getLocalPart(row.curi)] and getLocalPart(propName) != mappings[getLocalPart(row.curi)][\"@uniqueId\"]:\n",
        "          cypher.append(\"set n.\" + getLocalPart(propName) + \" = record.`\" + mappings[getLocalPart(row.curi)][getLocalPart(propName)] + \"`\")\n",
        "      cypher.append(\"return count(*) as total\") \n",
        "      cypher_import[getLocalPart(row.curi)] = ' \\n'.join(cypher)\n",
        "\n",
        "\n",
        "  rels_query = \"\"\"\n",
        "  prefix owl: <http://www.w3.org/2002/07/owl#> \n",
        "  prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
        "\n",
        "  SELECT DISTINCT ?rel ?dom ?ran #(GROUP_CONCAT(DISTINCT ?relTriplet ; SEPARATOR=\",\") AS ?rels)\n",
        "  WHERE {\n",
        "      ?rel a ?propertyClass .\n",
        "      filter(?propertyClass in (rdf:Property, owl:ObjectProperty, owl:FunctionalProperty, owl:AsymmetricProperty, \n",
        "            owl:InverseFunctionalProperty, owl:IrreflexiveProperty, owl:ReflexiveProperty, owl:SymmetricProperty, owl:TransitiveProperty))\n",
        "      \n",
        "      ?rel rdfs:domain ?dom ;\n",
        "        rdfs:range ?ran .\n",
        "      \n",
        "      #BIND (concat(str(?rel),';',str(?dom),';',str(?range)) AS ?relTriplet)\n",
        "      \n",
        "    }\"\"\"\n",
        "\n",
        "  for row in graph_onto_mapped.query(rels_query):\n",
        "    export_ns.add(getNamespacePart(row.rel))\n",
        "    export_mappings[getLocalPart(row.rel)] = str(row.rel)\n",
        "    cypher = []\n",
        "    cypher.append(\"unwind $records AS record\")\n",
        "    cypher.append(\"match (source:\" + getLocalPart(row.dom) + \" { `\" + mappings[getLocalPart(row.dom)][\"@uniqueId\"] + \"`: record.`\" + mappings[getLocalPart(row.rel)][\"@from\"] + \"`} )\")\n",
        "    cypher.append(\"match (target:\" + getLocalPart(row.ran) + \" { `\" + mappings[getLocalPart(row.ran)][\"@uniqueId\"] + \"`: record.`\" + mappings[getLocalPart(row.rel)][\"@to\"] + \"`} )\")\n",
        "    cypher.append(\"merge (source)-[r:`\"+ getLocalPart(row.rel) +\"`]->(target)\")\n",
        "    cypher.append(\"return count(*) as total\") \n",
        "    cypher_import[getLocalPart(row.rel)] = ' \\n'.join(cypher)\n",
        "\n",
        "\n",
        "  nscount = 0\n",
        "  mapping_export_cypher = []\n",
        "  \n",
        "  for ns in export_ns:\n",
        "    mapping_export_cypher.append(\"call n10s.nsprefixes.add('ns\" + str(nscount) + \"','\" + ns + \"');\")\n",
        "    nscount+=1\n",
        "\n",
        "  for k in export_mappings.keys():\n",
        "    mapping_export_cypher.append(\"call n10s.mapping.add('\" + export_mappings[k] + \"','\" + k + \"');\")\n",
        "\n",
        "  return cypher_import ,  mapping_export_cypher\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {
        "id": "tVikXP3oTs9K"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run getLoadersFromOnto\n",
            "using ontology S:/Users/Britt/Documents/Visual_Studio_GitHub/Visual_Studio_Code_Python/GoingMeta/session5/ontos/rail.ttl\n",
            "#LOADERS:\n",
            "\n",
            "Event: \n",
            "\n",
            "file: S:\\Users\\Britt\\Documents\\Visual_Studio_GitHub\\Visual_Studio_Code_Python\\GoingMeta\\session5\\data\\\\nr-events.csv\n",
            "\n",
            "unwind $records AS record \n",
            "merge (n:Event { `eventId`: record.`id`} ) \n",
            "set n.eventDescription = record.`desc` \n",
            "set n.eventType = record.`type` \n",
            "return count(*) as total\n",
            "\n",
            "\n",
            "Station: \n",
            "\n",
            "file: S:\\Users\\Britt\\Documents\\Visual_Studio_GitHub\\Visual_Studio_Code_Python\\GoingMeta\\session5\\data\\\\nr-stations-all.csv\n",
            "\n",
            "unwind $records AS record \n",
            "merge (n:Station { `stationCode`: record.`crs`} ) \n",
            "set n.lat = record.`lat` \n",
            "set n.long = record.`long` \n",
            "set n.stationAddress = record.`address` \n",
            "set n.stationName = record.`name` \n",
            "return count(*) as total\n",
            "\n",
            "\n",
            "affects: \n",
            "\n",
            "file: S:\\Users\\Britt\\Documents\\Visual_Studio_GitHub\\Visual_Studio_Code_Python\\GoingMeta\\session5\\data\\\\nr-events.csv\n",
            "\n",
            "unwind $records AS record \n",
            "match (source:Event { `eventId`: record.`id`} ) \n",
            "match (target:Station { `stationCode`: record.`Station`} ) \n",
            "merge (source)-[r:`affects`]->(target) \n",
            "return count(*) as total\n",
            "\n",
            "\n",
            "link: \n",
            "\n",
            "file: S:\\Users\\Britt\\Documents\\Visual_Studio_GitHub\\Visual_Studio_Code_Python\\GoingMeta\\session5\\data\\\\nr-station-links.csv\n",
            "\n",
            "unwind $records AS record \n",
            "match (source:Station { `stationCode`: record.`origin`} ) \n",
            "match (target:Station { `stationCode`: record.`destination`} ) \n",
            "merge (source)-[r:`link`]->(target) \n",
            "return count(*) as total\n",
            "\n",
            "\n",
            "#EXPORT MAPPINGS (for RDF API):\n",
            "\n",
            "call n10s.nsprefixes.add('ns0','http://onto.neo4j.com/rail#');\n",
            "call n10s.mapping.add('http://onto.neo4j.com/rail#Event','Event');\n",
            "call n10s.mapping.add('http://onto.neo4j.com/rail#eventDescription','eventDescription');\n",
            "call n10s.mapping.add('http://onto.neo4j.com/rail#eventId','eventId');\n",
            "call n10s.mapping.add('http://onto.neo4j.com/rail#eventType','eventType');\n",
            "call n10s.mapping.add('http://onto.neo4j.com/rail#Station','Station');\n",
            "call n10s.mapping.add('http://onto.neo4j.com/rail#lat','lat');\n",
            "call n10s.mapping.add('http://onto.neo4j.com/rail#long','long');\n",
            "call n10s.mapping.add('http://onto.neo4j.com/rail#stationAddress','stationAddress');\n",
            "call n10s.mapping.add('http://onto.neo4j.com/rail#stationCode','stationCode');\n",
            "call n10s.mapping.add('http://onto.neo4j.com/rail#stationName','stationName');\n",
            "call n10s.mapping.add('http://onto.neo4j.com/rail#affects','affects');\n",
            "call n10s.mapping.add('http://onto.neo4j.com/rail#link','link');\n"
          ]
        }
      ],
      "source": [
        "print(\"Run getLoadersFromOnto\")\n",
        "print(\"using ontology \" + onto)\n",
        "cypher_import , mapping_defs = getLoadersFromOnto(onto,\"turtle\",railMappings)\n",
        "\n",
        "print(\"#LOADERS:\\n\")\n",
        "for q in cypher_import.keys():\n",
        "  print(q + \": \\n\\nfile: \" + railMappings[q][\"@fileName\"] + \"\\n\\n\"+ cypher_import[q] + \"\\n\\n\")\n",
        "\n",
        "print(\"#EXPORT MAPPINGS (for RDF API):\\n\")\n",
        "for md in mapping_defs:\n",
        "  print(md)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {
        "id": "ztPHkOD8KNx3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Define insert_data to batch insert to the graph\n"
          ]
        }
      ],
      "source": [
        "# Utility function to write to Neo4j in batch mode.\n",
        "print(\"Define insert_data to batch insert to the graph\")\n",
        "\n",
        "def insert_data(session, query, frame, batch_size = 500):\n",
        "\n",
        "    total = 0\n",
        "    batch = 0\n",
        "    start = time.time()\n",
        "    result = None\n",
        "    \n",
        "    while batch * batch_size < len(frame):\n",
        "        res = session.write_transaction( lambda tx: tx.run(query,\n",
        "                      parameters = {'records': frame[batch*batch_size:(batch+1)*batch_size].to_dict('records')}).data())\n",
        "\n",
        "        total += res[0]['total']\n",
        "        batch += 1\n",
        "        result = {\"total\":total, \n",
        "                  \"batches\":batch, \n",
        "                  \"time\":time.time()-start}\n",
        "        print(result)\n",
        "        \n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This section is for Britt's CSU DevTest code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trying to connect to the Example Project instance: Movie DBMS\n",
            "\n",
            "bolt://localhost:7687\n"
          ]
        }
      ],
      "source": [
        "print(\"Trying to connect to the Example Project instance: Movie DBMS\\n\")\n",
        "\n",
        "my_auth=basic_auth(\"neo4j\", \"TestPswd\")\n",
        "neo4j_db_uri=\"bolt://localhost:7687\"\n",
        "print(neo4j_db_uri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DevTest code - neo4j driver connection to auraDB\n",
            "Trying to connect to my free neo4j Aura instance: Britt/CSU\n",
            "\n",
            "neo4j+s://5ba77883.databases.neo4j.io\n"
          ]
        }
      ],
      "source": [
        "print(\"DevTest code - neo4j driver connection to auraDB\")\n",
        "print(\"Trying to connect to my free neo4j Aura instance: Britt/CSU\\n\")\n",
        "# See notes in C:\\Users\\Britt\\OneDrive\\CSU\\Software_Tools\\neo4j\\Neo4j-5ba77883-Created-2024-09-27.txt\n",
        "my_auth=basic_auth(\"neo4j\", \"QWWDLjevJTXdWnmZqjXJFENM6_4k660WxN3aqr2SLSg\")\n",
        "neo4j_db_uri=\"neo4j+s://5ba77883.databases.neo4j.io\"\n",
        "#neo4j_db_uri=\"neo4j+s://5ba77883.databases.neo4j.io:7687\"\n",
        "print(neo4j_db_uri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "driver authentication:\n",
            "True\n",
            "driver connectivity:\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# driver = GraphDatabase.driver(\n",
        "#   \"bolt://3.84.57.61:7687\",\n",
        "#   auth=basic_auth(\"neo4j\", \"south-kettles-harmony\"))\n",
        "\n",
        "driver = GraphDatabase.driver(neo4j_db_uri, auth=my_auth)\n",
        "print(\"driver authentication:\")\n",
        "print(driver.verify_authentication())\n",
        "print(\"driver connectivity:\")\n",
        "print(driver.verify_connectivity())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "session for database:\n",
            "session verify_connectivity:\n",
            "<neo4j._sync.work.session.Session object at 0x00000220CDB44790>\n"
          ]
        }
      ],
      "source": [
        "print(\"session for database:\")\n",
        "#session = driver.session()\n",
        "session = driver.session(database=\"neo4j\")\n",
        "#session = driver.session(database=\"CSU_01\")\n",
        "#session = driver.session(database=\"neo4j\")\n",
        "#session = driver.session(database=\"neo4j\")\n",
        "print(\"session verify_connectivity:\")\n",
        "print(session)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['DoB1957']\n",
            "BYI\n",
            "[{'DoB1957': 'BYI'}, {'DoB1957': 'BME'}, {'DoB1957': 'KGT'}, {'DoB1957': 'LPG'}, {'DoB1957': 'PHG'}, {'DoB1957': 'ATB'}, {'DoB1957': 'HNK'}, {'DoB1957': 'SMD'}, {'DoB1957': 'THU'}, {'DoB1957': 'BOP'}, {'DoB1957': 'RYS'}, {'DoB1957': 'BWK'}, {'DoB1957': 'EXD'}, {'DoB1957': 'PIL'}, {'DoB1957': 'TRU'}, {'DoB1957': 'AUD'}, {'DoB1957': 'OUN'}, {'DoB1957': 'WRT'}, {'DoB1957': 'BBK'}, {'DoB1957': 'CAO'}, {'DoB1957': 'WYT'}, {'DoB1957': 'WCY'}, {'DoB1957': 'BMR'}, {'DoB1957': 'OPK'}, {'DoB1957': 'APP'}, {'DoB1957': 'BIY'}, {'DoB1957': 'DND'}, {'DoB1957': 'DTG'}, {'DoB1957': 'FOX'}, {'DoB1957': 'GST'}, {'DoB1957': 'LVM'}, {'DoB1957': 'SON'}, {'DoB1957': 'SWN'}, {'DoB1957': 'TOD'}, {'DoB1957': 'CIL'}, {'DoB1957': 'DVP'}, {'DoB1957': 'FKW'}, {'DoB1957': 'HYS'}, {'DoB1957': 'LFD'}, {'DoB1957': 'WHS'}, {'DoB1957': 'BNL'}, {'DoB1957': 'CAC'}, {'DoB1957': 'DBE'}, {'DoB1957': 'HST'}, {'DoB1957': 'KYL'}, {'DoB1957': 'LVG'}, {'DoB1957': 'NQU'}, {'DoB1957': 'PMT'}, {'DoB1957': 'SHL'}, {'DoB1957': 'ADV'}, {'DoB1957': 'BCU'}, {'DoB1957': 'FNC'}, {'DoB1957': 'WRM'}, {'DoB1957': 'WNS'}, {'DoB1957': 'WLS'}, {'DoB1957': 'RDT'}, {'DoB1957': 'MAC'}, {'DoB1957': 'BNG'}, {'DoB1957': 'CDF'}, {'DoB1957': 'FGW'}, {'DoB1957': 'LWM'}, {'DoB1957': 'BCF'}, {'DoB1957': 'BIT'}, {'DoB1957': 'KGS'}, {'DoB1957': 'SKM'}, {'DoB1957': 'CLM'}, {'DoB1957': 'GOX'}, {'DoB1957': 'LGM'}, {'DoB1957': 'LEI'}, {'DoB1957': 'NHL'}, {'DoB1957': 'RKT'}, {'DoB1957': 'DAR'}, {'DoB1957': 'DWW'}, {'DoB1957': 'MLW'}, {'DoB1957': 'SMC'}, {'DoB1957': 'SIP'}, {'DoB1957': 'WSB'}, {'DoB1957': 'AGR'}, {'DoB1957': 'BIS'}, {'DoB1957': 'NWA'}, {'DoB1957': 'SOF'}, {'DoB1957': 'CSL'}, {'DoB1957': 'GVH'}, {'DoB1957': 'KNN'}, {'DoB1957': 'WLN'}, {'DoB1957': 'CMD'}, {'DoB1957': 'LER'}, {'DoB1957': 'WAT'}, {'DoB1957': 'BMB'}, {'DoB1957': 'CRL'}, {'DoB1957': 'DOT'}, {'DoB1957': 'EGF'}, {'DoB1957': 'GSY'}, {'DoB1957': 'HSG'}, {'DoB1957': 'HEX'}, {'DoB1957': 'KSL'}, {'DoB1957': 'MHS'}, {'DoB1957': 'PFM'}, {'DoB1957': 'POP'}, {'DoB1957': 'WNN'}, {'DoB1957': 'WDS'}, {'DoB1957': 'AYH'}, {'DoB1957': 'DEA'}, {'DoB1957': 'GNH'}, {'DoB1957': 'SOR'}, {'DoB1957': 'SAJ'}, {'DoB1957': 'SMY'}, {'DoB1957': 'SFA'}, {'DoB1957': 'WHI'}, {'DoB1957': 'CDN'}, {'DoB1957': 'FGT'}, {'DoB1957': 'HEV'}, {'DoB1957': 'ARD'}, {'DoB1957': 'EDP'}, {'DoB1957': 'FRS'}, {'DoB1957': 'RTN'}, {'DoB1957': 'STG'}, {'DoB1957': 'LAN'}, {'DoB1957': 'FOG'}, {'DoB1957': 'IFD'}, {'DoB1957': 'CFC'}, {'DoB1957': 'CKY'}, {'DoB1957': 'MEV'}, {'DoB1957': 'MFA'}, {'DoB1957': 'SRG'}, {'DoB1957': 'BLP'}, {'DoB1957': 'ELO'}, {'DoB1957': 'HWI'}, {'DoB1957': 'BAY'}, {'DoB1957': 'GDH'}, {'DoB1957': 'EXC'}, {'DoB1957': 'LOS'}, {'DoB1957': 'SGM'}, {'DoB1957': 'WGV'}, {'DoB1957': 'RYH'}, {'DoB1957': 'BLX'}, {'DoB1957': 'HSD'}, {'DoB1957': 'SMA'}, {'DoB1957': 'OLD'}, {'DoB1957': 'BRW'}, {'DoB1957': 'HLR'}]\n",
            "\n",
            "# of Result Records = 141\n",
            "BYI\n",
            "BME\n",
            "KGT\n",
            "LPG\n",
            "PHG\n",
            "ATB\n",
            "HNK\n",
            "SMD\n",
            "THU\n",
            "BOP\n",
            "RYS\n",
            "BWK\n",
            "EXD\n",
            "PIL\n",
            "TRU\n",
            "AUD\n",
            "OUN\n",
            "WRT\n",
            "BBK\n",
            "CAO\n",
            "WYT\n",
            "WCY\n",
            "BMR\n",
            "OPK\n",
            "APP\n",
            "BIY\n",
            "DND\n",
            "DTG\n",
            "FOX\n",
            "GST\n",
            "LVM\n",
            "SON\n",
            "SWN\n",
            "TOD\n",
            "CIL\n",
            "DVP\n",
            "FKW\n",
            "HYS\n",
            "LFD\n",
            "WHS\n",
            "BNL\n",
            "CAC\n",
            "DBE\n",
            "HST\n",
            "KYL\n",
            "LVG\n",
            "NQU\n",
            "PMT\n",
            "SHL\n",
            "ADV\n",
            "BCU\n",
            "FNC\n",
            "WRM\n",
            "WNS\n",
            "WLS\n",
            "RDT\n",
            "MAC\n",
            "BNG\n",
            "CDF\n",
            "FGW\n",
            "LWM\n",
            "BCF\n",
            "BIT\n",
            "KGS\n",
            "SKM\n",
            "CLM\n",
            "GOX\n",
            "LGM\n",
            "LEI\n",
            "NHL\n",
            "RKT\n",
            "DAR\n",
            "DWW\n",
            "MLW\n",
            "SMC\n",
            "SIP\n",
            "WSB\n",
            "AGR\n",
            "BIS\n",
            "NWA\n",
            "SOF\n",
            "CSL\n",
            "GVH\n",
            "KNN\n",
            "WLN\n",
            "CMD\n",
            "LER\n",
            "WAT\n",
            "BMB\n",
            "CRL\n",
            "DOT\n",
            "EGF\n",
            "GSY\n",
            "HSG\n",
            "HEX\n",
            "KSL\n",
            "MHS\n",
            "PFM\n",
            "POP\n",
            "WNN\n",
            "WDS\n",
            "AYH\n",
            "DEA\n",
            "GNH\n",
            "SOR\n",
            "SAJ\n",
            "SMY\n",
            "SFA\n",
            "WHI\n",
            "CDN\n",
            "FGT\n",
            "HEV\n",
            "ARD\n",
            "EDP\n",
            "FRS\n",
            "RTN\n",
            "STG\n",
            "LAN\n",
            "FOG\n",
            "IFD\n",
            "CFC\n",
            "CKY\n",
            "MEV\n",
            "MFA\n",
            "SRG\n",
            "BLP\n",
            "ELO\n",
            "HWI\n",
            "BAY\n",
            "GDH\n",
            "EXC\n",
            "LOS\n",
            "SGM\n",
            "WGV\n",
            "RYH\n",
            "BLX\n",
            "HSD\n",
            "SMA\n",
            "OLD\n",
            "BRW\n",
            "HLR\n"
          ]
        }
      ],
      "source": [
        "qstr=\"MATCH (node:Station) RETURN node.Station as DoB1957\"\n",
        "#qstr=\"MATCH (node:Station) RETURN node.Station as DoB1957 LIMIT 5\"\n",
        "qresult = session.run(qstr)\n",
        "print(qresult.keys())\n",
        "\n",
        "qrec1=qresult.peek() #do not consume the next record from the result(s)\n",
        "print(qrec1.get(\"DoB1957\"))\n",
        "\n",
        "qdata=qresult.data(\"DoB1957\") #Result Data as list of dictionaries\n",
        "print(qdata)\n",
        "qn=len(qdata)\n",
        "print(\"\\n# of Result Records = \" + str(qn))\n",
        "\n",
        "for dict_i in qdata:\n",
        "    #print(\"\\n\")\n",
        "    #print(dict_i)\n",
        "    #print(dict_i.keys())\n",
        "    #print(dict_i.items())\n",
        "    #print(dict_i.values())\n",
        "    print(dict_i.get(\"DoB1957\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['DoB1957', 'DoB']\n",
            "Kevin Pollak\n",
            "1957\n",
            "[{'DoB1957': 'Kevin Pollak'}, {'DoB1957': 'Kelly McGillis'}, {'DoB1957': 'Cameron Crowe'}, {'DoB1957': 'Michael Clarke Duncan'}, {'DoB1957': 'Kevin Pollak'}, {'DoB1957': 'Kelly McGillis'}, {'DoB1957': 'Cameron Crowe'}, {'DoB1957': 'Michael Clarke Duncan'}]\n",
            "\n",
            "# of Result Records = 8\n",
            "Kevin Pollak\n",
            "Kelly McGillis\n",
            "Cameron Crowe\n",
            "Michael Clarke Duncan\n",
            "Kevin Pollak\n",
            "Kelly McGillis\n",
            "Cameron Crowe\n",
            "Michael Clarke Duncan\n"
          ]
        }
      ],
      "source": [
        "#:dbs\n",
        "#:use neo4j\n",
        "#:sysinfo\n",
        "\n",
        "#qstr=\"MATCH (n:Person) RETURN n LIMIT 25\"\n",
        "qstr=\"MATCH (node:Person {born: 1957}) RETURN node LIMIT 25\"\n",
        "qstr=\"MATCH (node:Person {born: 1957}) RETURN node.name LIMIT 25\"\n",
        "qstr=\"MATCH (node:Person {born: 1957}) RETURN node as DoB1957 LIMIT 25\"\n",
        "qstr=\"MATCH (node:Person {born: 1957}) RETURN node.name as DoB1957, node.born as DoB LIMIT 25\"\n",
        "\n",
        "qresult = session.run(qstr)\n",
        "print(qresult.keys())\n",
        "\n",
        "#qresult.value()\n",
        "#qresult.values(0)\n",
        "\n",
        "#qrec1=qresult.fetch(1) #consume the next record from the result(s)\n",
        "qrec1=qresult.peek() #do not consume the next record from the result(s)\n",
        "print(qrec1.get(\"DoB1957\"))\n",
        "print(qrec1.get(\"DoB\"))\n",
        "\n",
        "#qresult.values(\"node\")\n",
        "#qresult.values(\"node.name\")\n",
        "#qresult.values(\"DoB1957\") #Result Values\n",
        "#qresult.data(\"DoB1957\") #Result Data\n",
        "qdata=qresult.data(\"DoB1957\") #Result Data as list of dictionaries\n",
        "#qdata=qresult.data(\"DoB\")\n",
        "print(qdata)\n",
        "qn=len(qdata)\n",
        "print(\"\\n# of Result Records = \" + str(qn))\n",
        "for dict_i in qdata:\n",
        "    #print(\"\\n\")\n",
        "    #print(dict_i)\n",
        "    #print(dict_i.keys())\n",
        "    #print(dict_i.items())\n",
        "    #print(dict_i.values())\n",
        "    print(dict_i.get(\"DoB1957\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DevTest code\n"
          ]
        }
      ],
      "source": [
        "print(\"DevTest code\")\n",
        "\n",
        "# print(\"Results from previous getLoadersFromOnto\")\n",
        "# print(\"#LOADERS:\\n\")\n",
        "# for q in cypher_import.keys():\n",
        "#   print(q + \": \\n\\nfile: \" + railMappings[q][\"@fileName\"] + \"\\n\\n\"+ cypher_import[q] + \"\\n\\n\")\n",
        "\n",
        "# print(\"#EXPORT MAPPINGS (for RDF API):\\n\")\n",
        "# for md in mapping_defs:\n",
        "#   print(md)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "about to import Event from file S:\\Users\\Britt\\Documents\\Visual_Studio_GitHub\\Visual_Studio_Code_Python\\GoingMeta\\session5\\data\\\\nr-events.csv\n",
            "       id Station               type                   ts  \\\n",
            "0    1144     BYI  Maintenance Works  2021-08-06 18:28:21   \n",
            "1    4958     BME  Maintenance Works  2022-04-24 12:23:06   \n",
            "2    4152     KGT  Maintenance Works  2022-02-22 00:09:18   \n",
            "3    7233     LPG  Maintenance Works  2021-08-30 11:24:00   \n",
            "4    5223     PHG  Maintenance Works  2021-09-30 05:49:01   \n",
            "..    ...     ...                ...                  ...   \n",
            "138  3049     SMA  Track Obstruction  2022-04-15 05:38:35   \n",
            "139  1589     LER  Track Obstruction  2021-09-29 04:42:53   \n",
            "140  6719     OLD  Track Obstruction  2022-01-03 14:27:13   \n",
            "141  6405     BRW  Track Obstruction  2021-08-30 22:28:09   \n",
            "142  8693     HLR  Track Obstruction  2021-08-05 16:48:17   \n",
            "\n",
            "                                                  desc  \n",
            "0    Nunc nisl. Duis bibendum, felis sed interdum v...  \n",
            "1    Donec ut dolor. Morbi vel lectus in quam fring...  \n",
            "2    Nunc rhoncus dui vel sem. Sed sagittis. Nam co...  \n",
            "3    Proin eu mi. Nulla ac enim. In tempor, turpis ...  \n",
            "4    In hac habitasse platea dictumst. Maecenas ut ...  \n",
            "..                                                 ...  \n",
            "138  Ut tellus. Nulla ut erat id mauris vulputate e...  \n",
            "139  Pellentesque ultrices mattis odio. Donec vitae...  \n",
            "140  Nunc purus. Phasellus in felis. Donec semper s...  \n",
            "141  Maecenas leo odio, condimentum id, luctus nec,...  \n",
            "142  Proin at turpis a pede posuere nonummy. Intege...  \n",
            "\n",
            "[143 rows x 5 columns]\n",
            "about to import Station from file S:\\Users\\Britt\\Documents\\Visual_Studio_GitHub\\Visual_Studio_Code_Python\\GoingMeta\\session5\\data\\\\nr-stations-all.csv\n",
            "      crs nationalLocationCode                                          name  \\\n",
            "0     ABE               381300                                          Aber   \n",
            "1     ACY               380100                                     Abercynon   \n",
            "2     ABA               398200                                      Aberdare   \n",
            "3     AVY               443500                                     Aberdovey   \n",
            "4     ABH               444000                                      Abererch   \n",
            "...   ...                  ...                                           ...   \n",
            "2588  SIA               478700                              Southend Airport   \n",
            "2589  HAF               709100       Heathrow Terminal 4 (Rail Station Only)   \n",
            "2590  HWV                 9846       Heathrow Terminal 5 (Rail Station Only)   \n",
            "2591  HXX               709000  Heathrow Terminals 2 & 3 (Rail Station Only)   \n",
            "2592  CFC                 7765                                  Corfe Castle   \n",
            "\n",
            "     sixteenCharacterName                                            address  \\\n",
            "0                    ABER  Aber station, Nantgarw Road, Aber, Caerphilly,...   \n",
            "1               ABERCYNON  Abercynon station, Station Road, Abercynon, Rh...   \n",
            "2                ABERDARE  Aberdare station, Abernant Road, Aberdare, Mid...   \n",
            "3               ABERDOVEY  Aberdovey station, Station Road, Aberdovey, Gw...   \n",
            "4                ABERERCH  Abererch station, Abererch Sands Road, Aberech...   \n",
            "...                   ...                                                ...   \n",
            "2588     Southend Airport  Southend Airport station, Southend-on-Sea, Ess...   \n",
            "2589       HEATHROW EXP 4  Heathrow Airport Terminal 4 station, Southern ...   \n",
            "2590       HEATHROW EXP 5  Heathrow Airport Terminal 5 station, Terminal ...   \n",
            "2591     HEATHROW EXP 123  Heathrow Airport Terminals 2 & 3 st, Inner Rin...   \n",
            "2592                  CFC  Corfe Castle station, Station Road, Corfe Cast...   \n",
            "\n",
            "          long        lat                                                uri  \n",
            "0    -3.229839  51.574961  https://www.nationalrail.co.uk/stations/ABE/de...  \n",
            "1    -3.327001  51.644706  https://www.nationalrail.co.uk/stations/ACY/de...  \n",
            "2    -3.443099  51.715057  https://www.nationalrail.co.uk/stations/ABA/de...  \n",
            "3    -4.057081  52.543972  https://www.nationalrail.co.uk/stations/AVY/de...  \n",
            "4    -4.374196  52.898600  https://www.nationalrail.co.uk/stations/ABH/de...  \n",
            "...        ...        ...                                                ...  \n",
            "2588  0.704052  51.568691  https://www.nationalrail.co.uk/stations/SIA/de...  \n",
            "2589 -0.445454  51.458271  https://www.nationalrail.co.uk/stations/HAF/de...  \n",
            "2590 -0.490581  51.470057  https://www.nationalrail.co.uk/stations/HWV/de...  \n",
            "2591 -0.450720  51.472730  https://www.nationalrail.co.uk/stations/HXX/de...  \n",
            "2592 -2.055308  50.637753  https://www.nationalrail.co.uk/stations/CFC/de...  \n",
            "\n",
            "[2593 rows x 8 columns]\n",
            "about to import affects from file S:\\Users\\Britt\\Documents\\Visual_Studio_GitHub\\Visual_Studio_Code_Python\\GoingMeta\\session5\\data\\\\nr-events.csv\n",
            "       id Station               type                   ts  \\\n",
            "0    1144     BYI  Maintenance Works  2021-08-06 18:28:21   \n",
            "1    4958     BME  Maintenance Works  2022-04-24 12:23:06   \n",
            "2    4152     KGT  Maintenance Works  2022-02-22 00:09:18   \n",
            "3    7233     LPG  Maintenance Works  2021-08-30 11:24:00   \n",
            "4    5223     PHG  Maintenance Works  2021-09-30 05:49:01   \n",
            "..    ...     ...                ...                  ...   \n",
            "138  3049     SMA  Track Obstruction  2022-04-15 05:38:35   \n",
            "139  1589     LER  Track Obstruction  2021-09-29 04:42:53   \n",
            "140  6719     OLD  Track Obstruction  2022-01-03 14:27:13   \n",
            "141  6405     BRW  Track Obstruction  2021-08-30 22:28:09   \n",
            "142  8693     HLR  Track Obstruction  2021-08-05 16:48:17   \n",
            "\n",
            "                                                  desc  \n",
            "0    Nunc nisl. Duis bibendum, felis sed interdum v...  \n",
            "1    Donec ut dolor. Morbi vel lectus in quam fring...  \n",
            "2    Nunc rhoncus dui vel sem. Sed sagittis. Nam co...  \n",
            "3    Proin eu mi. Nulla ac enim. In tempor, turpis ...  \n",
            "4    In hac habitasse platea dictumst. Maecenas ut ...  \n",
            "..                                                 ...  \n",
            "138  Ut tellus. Nulla ut erat id mauris vulputate e...  \n",
            "139  Pellentesque ultrices mattis odio. Donec vitae...  \n",
            "140  Nunc purus. Phasellus in felis. Donec semper s...  \n",
            "141  Maecenas leo odio, condimentum id, luctus nec,...  \n",
            "142  Proin at turpis a pede posuere nonummy. Intege...  \n",
            "\n",
            "[143 rows x 5 columns]\n",
            "about to import link from file S:\\Users\\Britt\\Documents\\Visual_Studio_GitHub\\Visual_Studio_Code_Python\\GoingMeta\\session5\\data\\\\nr-station-links.csv\n",
            "     origin destination  distance\n",
            "0       AAP         BOP      0.71\n",
            "1       AAP         HRN      0.93\n",
            "2       AAP         NSG      1.46\n",
            "3       AAT         ACN      6.48\n",
            "4       AAT         LCC      4.18\n",
            "...     ...         ...       ...\n",
            "5797    ZCW         SQE      0.33\n",
            "5798    ZFD         CTK      0.34\n",
            "5799    ZFD         STP      1.21\n",
            "5800    ZLW         SDC      0.72\n",
            "5801    ZLW         SDE      0.62\n",
            "\n",
            "[5802 rows x 3 columns]\n",
            "S:\\Users\\Britt\\Documents\\Visual_Studio_GitHub\\Visual_Studio_Code_Python\\GoingMeta\\session5\\data\\\\new_links.csv\n"
          ]
        }
      ],
      "source": [
        "for q in cypher_import.keys():\n",
        "  print(\"about to import \" + q + \" from file \" + railMappings[q][\"@fileName\"])\n",
        "  df = pd.read_csv(railMappings[q][\"@fileName\"])\n",
        "  print(df)\n",
        "\n",
        "  #result = insert_data(session, cypher_import[q], df, batch_size = 300) \n",
        "  #print(result)\n",
        "  \n",
        "  #load csv from 'file:///artists.csv' AS row\n",
        "  #LOAD CSV from railMappings[q][\"@fileName\"] AS row\n",
        "  \n",
        "  #print(\"How do you create a data_frame from a .csv file?\")\n",
        "  #insert_data(session, cypher_import[q], data_frame, batch_size=300)\n",
        "\n",
        "\n",
        "# Delete nodes and all attached relationships\n",
        "#MATCH (n:Station)\n",
        "#DETACH DELETE n\n",
        "\n",
        "# Delete all relationships\n",
        "#MATCH ()-[n]-() DELETE n\n",
        "#MATCH ()-[n:LINK_TO]-() DELETE n\n",
        "\n",
        "# Create a relationship (and the assoc. nodes)\n",
        "#CREATE (src_node:Person {name: 'Charlie Sheen'})-[:ACTED_IN {rel_prop: 'prop1'}]->(wallStreet:Movie {title: 'Wall Street'})<-[:DIRECTED]-(dest_node:Person:Director {name: 'Oliver Stone'})\n",
        "# Create a relationship (using existing nodes)\n",
        "# Create a relationship (between existing nodes)\n",
        "#MATCH (src_node:Station {Station: 'PHG'}), (dest_node:Station {Station: 'ATB'})\n",
        "#CREATE (src_node)-[:LINK_TO {rel_prop: 'prop1'}]->(dest_node)\n",
        "\n",
        "# Import Node from .csv\n",
        "\n",
        "print(import_csv_file)\n",
        "#LOAD CSV FROM 'file:///new_links.csv' AS row\n",
        "#MERGE (a:Artist {origin: row[1], destination: row[2], distance: toInteger(row[3])})\n",
        "#RETURN a.origin, a.destination, a.distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing session and driver\n"
          ]
        }
      ],
      "source": [
        "print(\"Closing session and driver\")\n",
        "session.close()\n",
        "driver.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Now you may want to follow the tutorial \n",
            "https://neo4j.com/docs/getting-started/appendix/tutorials/guide-import-relational-and-etl/ for \n",
            "Creating Order nodes \n",
            "Creating the indexes and constraints for the data in the graph\n"
          ]
        }
      ],
      "source": [
        "print(\"Now you may want to follow the tutorial \\nhttps://neo4j.com/docs/getting-started/appendix/tutorials/guide-import-relational-and-etl/ for \\nCreating nodes \\nCreating the indexes and constraints for the data in the graph\")\n",
        "print (\"\\nThis may explain the routine pd.read_csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2b4j854JkAO"
      },
      "outputs": [],
      "source": [
        "print(\"Connect to a neo4j sandbox\")\n",
        "driver = GraphDatabase.driver(\n",
        "  \"bolt://3.84.57.61:7687\",\n",
        "  auth=basic_auth(\"neo4j\", \"south-kettles-harmony\"))\n",
        "\n",
        "session = driver.session(database=\"neo4j\")\n",
        "\n",
        "#cypher_import , mapping_defs = getLoadersFromOnto(onto,\"turtle\",railMappings)\n",
        "\n",
        "for q in cypher_import.keys():\n",
        "  print(\"about to import \" + q + \" from file \" + railMappings[q][\"@fileName\"])\n",
        "  df = pd.read_csv(railMappings[q][\"@fileName\"])\n",
        "  print(df)\n",
        "  #result = insert_data(session, cypher_import[q], df, batch_size = 300) \n",
        "  #print(result)\n",
        "\n",
        "for md in mapping_defs:\n",
        "  session.run(md)\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPa90V5qw4Hy/CLydkkxIwD",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Ontology Driven KG creation",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
