{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbarrasa/goingmeta/blob/main/session5/Ontology_Driven_KG_creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhuV0UJzbekv"
      },
      "outputs": [],
      "source": [
        "pip install rdflib neo4j pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "qf3yMwgyVg05"
      },
      "outputs": [],
      "source": [
        "import rdflib, time\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "\n",
        "from neo4j import GraphDatabase, basic_auth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Britt settings:\")\n",
        "data_dir=\"https://raw.githubusercontent.com/jbarrasa/goingmeta/main/session5/data/\"\n",
        "data_dir=r\"S:\\Users\\Britt\\Documents\\Visual_Studio_GitHub\\Visual_Studio_Code_Python\\GoingMeta\\session5\\data\" + r\"\\\\\"\n",
        "#print(data_dir)\n",
        "print(pathlib.Path(data_dir))\n",
        "\n",
        "onto = \"https://raw.githubusercontent.com/jbarrasa/goingmeta/main/session5/ontos/rail.ttl\"\n",
        "onto = \"S:/Users/Britt/Documents/Visual_Studio_GitHub/Visual_Studio_Code_Python/GoingMeta/session5/ontos/rail.ttl\"\n",
        "print(onto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRYK8Uvk67jQ"
      },
      "outputs": [],
      "source": [
        "#utility function to get the local part of a URI (stripping out the namespace)\n",
        "print(\"Verify rdf ontology functions getLocalPart and getNamespacePart\")\n",
        "\n",
        "def getLocalPart(uri):\n",
        "  pos = -1\n",
        "  pos = uri.rfind('#') \n",
        "  if pos < 0 :\n",
        "    pos = uri.rfind('/')  \n",
        "  if pos < 0 :\n",
        "    pos = uri.rindex(':')\n",
        "  return uri[pos+1:]\n",
        "\n",
        "def getNamespacePart(uri):\n",
        "  pos = -1\n",
        "  pos = uri.rfind('#') \n",
        "  if pos < 0 :\n",
        "    pos = uri.rfind('/')  \n",
        "  if pos < 0 :\n",
        "    pos = uri.rindex(':')\n",
        "  return uri[0:pos+1]\n",
        "\n",
        "# quick test\n",
        "print(getLocalPart(\"http://onto.neo4j.com/rail#Station\"))\n",
        "print(getNamespacePart(\"http://onto.neo4j.com/rail#Station\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_oshqtSP_fe"
      },
      "outputs": [],
      "source": [
        "# processing the ontology...\n",
        "print(\"Create graph from rdf ontology\")\n",
        "print(onto)\n",
        "\n",
        "graph_onto = rdflib.Graph()\n",
        "graph_onto.parse(onto, format='turtle')\n",
        "\n",
        "graph_query_classes = \"\"\"\n",
        "prefix owl: <http://www.w3.org/2002/07/owl#> \n",
        "prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
        "SELECT DISTINCT ?c\n",
        "  WHERE {\n",
        "    ?c rdf:type owl:Class .    \n",
        "  } \"\"\"\n",
        "print(\"\\nQuery graph for all owl:Class\")\n",
        "for row in graph_onto.query(graph_query_classes):\n",
        "    print(str(row.c), getLocalPart(str(row.c)), getNamespacePart(str(row.c)))\n",
        "\n",
        "graph_query_properties = \"\"\"\n",
        "prefix owl: <http://www.w3.org/2002/07/owl#> \n",
        "prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
        "SELECT DISTINCT ?c\n",
        "  WHERE {\n",
        "    ?c rdf:type owl:ObjectProperty .    \n",
        "  } \"\"\"\n",
        "print(\"\\nQuery graph for all owl:ObjectProperty\")\n",
        "for row in graph_onto.query(graph_query_properties):\n",
        "    print(str(row.c), getLocalPart(str(row.c)), getNamespacePart(str(row.c)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jtsSEJnbtVq"
      },
      "outputs": [],
      "source": [
        "# read the onto and generate cypher (complete without mappings)\n",
        "print(\"Generate cypher query from ontology (without mappings)\")\n",
        "\n",
        "classes_and_props_query = \"\"\"\n",
        "prefix owl: <http://www.w3.org/2002/07/owl#> \n",
        "prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
        "\n",
        "SELECT DISTINCT ?curi (GROUP_CONCAT(DISTINCT ?propTypePair ; SEPARATOR=\",\") AS ?props)\n",
        "WHERE {\n",
        "    ?curi rdf:type owl:Class .\n",
        "    optional { \n",
        "      ?prop rdfs:domain ?curi ;\n",
        "        a owl:DatatypeProperty ;\n",
        "        rdfs:range ?range .\n",
        "      BIND (concat(str(?prop),';',str(?range)) AS ?propTypePair)\n",
        "    }\n",
        "  } GROUP BY ?curi  \"\"\"\n",
        "\n",
        "cypher_list = []\n",
        "\n",
        "for row in graph_onto.query(classes_and_props_query):\n",
        "    cypher = []\n",
        "    cypher.append(\"unwind $records AS record\")\n",
        "    cypher.append(\"merge (n:\" + getLocalPart(row.curi) + \" { `<id_prop>`: record.`<col with id>`} )\")\n",
        "    for pair in row.props.split(\",\"):\n",
        "      propName = pair.split(\";\")[0]\n",
        "      propType = pair.split(\";\")[1]\n",
        "      cypher.append(\"set n.\" + getLocalPart(propName) + \" = record.`<col with value for \" + getLocalPart(propName) + \">`\")\n",
        "    cypher.append(\"return count(*) as total\") \n",
        "    cypher_list.append(' \\n'.join(cypher))\n",
        "\n",
        "\n",
        "rels_query = \"\"\"\n",
        "prefix owl: <http://www.w3.org/2002/07/owl#> \n",
        "prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
        "\n",
        "SELECT DISTINCT ?rel ?dom ?ran #(GROUP_CONCAT(DISTINCT ?relTriplet ; SEPARATOR=\",\") AS ?rels)\n",
        "WHERE {\n",
        "    ?rel a ?propertyClass .\n",
        "    filter(?propertyClass in (rdf:Property, owl:ObjectProperty, owl:FunctionalProperty, owl:AsymmetricProperty, \n",
        "           owl:InverseFunctionalProperty, owl:IrreflexiveProperty, owl:ReflexiveProperty, owl:SymmetricProperty, owl:TransitiveProperty))\n",
        "    \n",
        "    ?rel rdfs:domain ?dom ;\n",
        "      rdfs:range ?ran .\n",
        "    \n",
        "    #BIND (concat(str(?rel),';',str(?dom),';',str(?range)) AS ?relTriplet)\n",
        "    \n",
        "  }\"\"\"\n",
        "\n",
        "\n",
        "for row in graph_onto.query(rels_query):\n",
        "  cypher = []\n",
        "  cypher.append(\"unwind $records AS record\")\n",
        "  cypher.append(\"match (source:\" + getLocalPart(row.dom) + \" { `<id_prop>`: record.`<col with source id>`} )\")\n",
        "  cypher.append(\"match (target:\" + getLocalPart(row.ran) + \" { `<id_prop>`: record.`<col with target id>`} )\")\n",
        "  cypher.append(\"merge (source)-[r:`\"+ getLocalPart(row.rel) +\"`]->(target)\")\n",
        "  cypher.append(\"return count(*) as total\") \n",
        "  cypher_list.append(' \\n'.join(cypher))\n",
        "\n",
        "print(\"\\nList of generated cypher queries\")\n",
        "for q in cypher_list:\n",
        "  print(\"\\n\" + q)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4GP70jAf8v2"
      },
      "outputs": [],
      "source": [
        "print(\"Define mappings: rail, station, event, link, affects\")\n",
        "\n",
        "railMappings = {}\n",
        "stationMapping = {}\n",
        "eventMapping = {}\n",
        "linkMapping = {}\n",
        "affectsMapping = {}\n",
        "\n",
        "print(pathlib.Path(data_dir + \"nr-stations-all.csv\"))\n",
        "\n",
        "stationMapping[\"@fileName\"] = data_dir + \"nr-stations-all.csv\"\n",
        "stationMapping[\"@uniqueId\"] = \"stationCode\"\n",
        "stationMapping[\"lat\"] = \"lat\"\n",
        "stationMapping[\"long\"] = \"long\"\n",
        "stationMapping[\"stationAddress\"] = \"address\"\n",
        "stationMapping[\"stationCode\"] = \"crs\"\n",
        "stationMapping[\"stationName\"] = \"name\"\n",
        "railMappings[\"Station\"] = stationMapping\n",
        "\n",
        "eventMapping[\"@fileName\"] = data_dir + \"nr-events.csv\"\n",
        "eventMapping[\"@uniqueId\"] = \"eventId\"\n",
        "eventMapping[\"eventDescription\"] = \"desc\"\n",
        "eventMapping[\"eventId\"] = \"id\"\n",
        "eventMapping[\"timestamp\"] = \"ts\"\n",
        "eventMapping[\"eventType\"] = \"type\"\n",
        "railMappings[\"Event\"] = eventMapping\n",
        "\n",
        "linkMapping[\"@fileName\"] = data_dir + \"nr-station-links.csv\"\n",
        "linkMapping[\"@from\"] = \"origin\"\n",
        "linkMapping[\"@to\"] = \"destination\"\n",
        "railMappings[\"link\"] = linkMapping\n",
        "\n",
        "affectsMapping[\"@fileName\"] = data_dir + \"nr-events.csv\"\n",
        "affectsMapping[\"@from\"] = \"id\"\n",
        "affectsMapping[\"@to\"] = \"Station\"\n",
        "railMappings[\"affects\"] = affectsMapping\n",
        "\n",
        "# show it?\n",
        "print(\"\\nExample mappings: railMappings\")\n",
        "railMappings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ouw2B3BmHhn5"
      },
      "outputs": [],
      "source": [
        "#copy of previous but using the mappings\n",
        "print(\"Define getLoadersFromOnto to repeat process with mappings\")\n",
        "\n",
        "def getLoadersFromOnto(onto, rdf_format, mappings):\n",
        "  graph_onto_mapped = rdflib.Graph()\n",
        "  graph_onto_mapped.parse(onto, format= rdf_format)\n",
        "\n",
        "  classes_and_props_query = \"\"\"\n",
        "  prefix owl: <http://www.w3.org/2002/07/owl#> \n",
        "  prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
        "\n",
        "  SELECT DISTINCT ?curi (GROUP_CONCAT(DISTINCT ?propTypePair ; SEPARATOR=\",\") AS ?props)\n",
        "  WHERE {\n",
        "      ?curi rdf:type owl:Class .\n",
        "      optional { \n",
        "        ?prop rdfs:domain ?curi ;\n",
        "          a owl:DatatypeProperty ;\n",
        "          rdfs:range ?range .\n",
        "        BIND (concat(str(?prop),';',str(?range)) AS ?propTypePair)\n",
        "      }\n",
        "    } GROUP BY ?curi  \"\"\"\n",
        "\n",
        "  cypher_import = {}\n",
        "  export_ns = set()\n",
        "  export_mappings = {}\n",
        "\n",
        "  for row in graph_onto_mapped.query(classes_and_props_query):\n",
        "      export_ns.add(getNamespacePart(row.curi))\n",
        "      export_mappings[getLocalPart(row.curi)] = str(row.curi)\n",
        "      cypher = []\n",
        "      cypher.append(\"unwind $records AS record\")\n",
        "      cypher.append(\"merge (n:\" + getLocalPart(row.curi) + \" { `\" + mappings[getLocalPart(row.curi)][\"@uniqueId\"] + \"`: record.`\" + mappings[getLocalPart(row.curi)][mappings[getLocalPart(row.curi)][\"@uniqueId\"]] + \"`} )\")\n",
        "      for pair in row.props.split(\",\"):      \n",
        "        propName = pair.split(\";\")[0]\n",
        "        propType = pair.split(\";\")[1]\n",
        "        export_ns.add(getNamespacePart(propName))\n",
        "        export_mappings[getLocalPart(propName)] = propName\n",
        "        #if a mapping (a column in the source file) is defined for the property and property is not a unique id\n",
        "        if getLocalPart(propName) in mappings[getLocalPart(row.curi)] and getLocalPart(propName) != mappings[getLocalPart(row.curi)][\"@uniqueId\"]:\n",
        "          cypher.append(\"set n.\" + getLocalPart(propName) + \" = record.`\" + mappings[getLocalPart(row.curi)][getLocalPart(propName)] + \"`\")\n",
        "      cypher.append(\"return count(*) as total\") \n",
        "      cypher_import[getLocalPart(row.curi)] = ' \\n'.join(cypher)\n",
        "\n",
        "\n",
        "  rels_query = \"\"\"\n",
        "  prefix owl: <http://www.w3.org/2002/07/owl#> \n",
        "  prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
        "\n",
        "  SELECT DISTINCT ?rel ?dom ?ran #(GROUP_CONCAT(DISTINCT ?relTriplet ; SEPARATOR=\",\") AS ?rels)\n",
        "  WHERE {\n",
        "      ?rel a ?propertyClass .\n",
        "      filter(?propertyClass in (rdf:Property, owl:ObjectProperty, owl:FunctionalProperty, owl:AsymmetricProperty, \n",
        "            owl:InverseFunctionalProperty, owl:IrreflexiveProperty, owl:ReflexiveProperty, owl:SymmetricProperty, owl:TransitiveProperty))\n",
        "      \n",
        "      ?rel rdfs:domain ?dom ;\n",
        "        rdfs:range ?ran .\n",
        "      \n",
        "      #BIND (concat(str(?rel),';',str(?dom),';',str(?range)) AS ?relTriplet)\n",
        "      \n",
        "    }\"\"\"\n",
        "\n",
        "  for row in graph_onto_mapped.query(rels_query):\n",
        "    export_ns.add(getNamespacePart(row.rel))\n",
        "    export_mappings[getLocalPart(row.rel)] = str(row.rel)\n",
        "    cypher = []\n",
        "    cypher.append(\"unwind $records AS record\")\n",
        "    cypher.append(\"match (source:\" + getLocalPart(row.dom) + \" { `\" + mappings[getLocalPart(row.dom)][\"@uniqueId\"] + \"`: record.`\" + mappings[getLocalPart(row.rel)][\"@from\"] + \"`} )\")\n",
        "    cypher.append(\"match (target:\" + getLocalPart(row.ran) + \" { `\" + mappings[getLocalPart(row.ran)][\"@uniqueId\"] + \"`: record.`\" + mappings[getLocalPart(row.rel)][\"@to\"] + \"`} )\")\n",
        "    cypher.append(\"merge (source)-[r:`\"+ getLocalPart(row.rel) +\"`]->(target)\")\n",
        "    cypher.append(\"return count(*) as total\") \n",
        "    cypher_import[getLocalPart(row.rel)] = ' \\n'.join(cypher)\n",
        "\n",
        "\n",
        "  nscount = 0\n",
        "  mapping_export_cypher = []\n",
        "  \n",
        "  for ns in export_ns:\n",
        "    mapping_export_cypher.append(\"call n10s.nsprefixes.add('ns\" + str(nscount) + \"','\" + ns + \"');\")\n",
        "    nscount+=1\n",
        "\n",
        "  for k in export_mappings.keys():\n",
        "    mapping_export_cypher.append(\"call n10s.mapping.add('\" + export_mappings[k] + \"','\" + k + \"');\")\n",
        "\n",
        "  return cypher_import ,  mapping_export_cypher\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVikXP3oTs9K"
      },
      "outputs": [],
      "source": [
        "print(\"Run getLoadersFromOnto\")\n",
        "print(\"using ontology \" + onto)\n",
        "cypher_import , mapping_defs = getLoadersFromOnto(onto,\"turtle\",railMappings)\n",
        "\n",
        "print(\"#LOADERS:\\n\")\n",
        "for q in cypher_import.keys():\n",
        "  print(q + \": \\n\\nfile: \" + railMappings[q][\"@fileName\"] + \"\\n\\n\"+ cypher_import[q] + \"\\n\\n\")\n",
        "\n",
        "print(\"#EXPORT MAPPINGS (for RDF API):\\n\")\n",
        "for md in mapping_defs:\n",
        "  print(md)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztPHkOD8KNx3"
      },
      "outputs": [],
      "source": [
        "# Utility function to write to Neo4j in batch mode.\n",
        "print(\"Define insert_data to batch insert to the graph\")\n",
        "\n",
        "def insert_data(session, query, frame, batch_size = 500):\n",
        "\n",
        "    total = 0\n",
        "    batch = 0\n",
        "    start = time.time()\n",
        "    result = None\n",
        "    \n",
        "    while batch * batch_size < len(frame):\n",
        "        res = session.write_transaction( lambda tx: tx.run(query,\n",
        "                      parameters = {'records': frame[batch*batch_size:(batch+1)*batch_size].to_dict('records')}).data())\n",
        "\n",
        "        total += res[0]['total']\n",
        "        batch += 1\n",
        "        result = {\"total\":total, \n",
        "                  \"batches\":batch, \n",
        "                  \"time\":time.time()-start}\n",
        "        print(result)\n",
        "        \n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This section is for Britt's CSU DevTest code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"DevTest code\")\n",
        "\n",
        "print(\"Trying to connect to my free neo4j Aura instance: Britt/CSU\")\n",
        "neo4j_db_uri=\"neo4j+s://5ba77883.databases.neo4j.io\"\n",
        "print(neo4j_db_uri)\n",
        "\n",
        "# driver = GraphDatabase.driver(\n",
        "#   \"bolt://3.84.57.61:7687\",\n",
        "#   auth=basic_auth(\"neo4j\", \"south-kettles-harmony\"))\n",
        "driver = GraphDatabase.driver(\n",
        "  neo4j_db_uri,\n",
        "  auth=basic_auth(\"neo4j\", \"QWWDLjevJTXdWnmZqjXJFENM6_4k660WxN3aqr2SLSg\"))\n",
        "\n",
        "print(driver.verify_authentication())\n",
        "print(driver.verify_connectivity())\n",
        "\n",
        "\n",
        "session = driver.session(database=\"CSU_01\")\n",
        "print(driver.verify_connectivity())\n",
        "session = driver.session(database=\"5ba77883\")\n",
        "print(driver.verify_connectivity())\n",
        "\n",
        "print(\"Created driver session\")\n",
        "\n",
        "# print(\"Results from previous getLoadersFromOnto\")\n",
        "# print(\"#LOADERS:\\n\")\n",
        "# for q in cypher_import.keys():\n",
        "#   print(q + \": \\n\\nfile: \" + railMappings[q][\"@fileName\"] + \"\\n\\n\"+ cypher_import[q] + \"\\n\\n\")\n",
        "\n",
        "# print(\"#EXPORT MAPPINGS (for RDF API):\\n\")\n",
        "# for md in mapping_defs:\n",
        "#   print(md)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for q in cypher_import.keys():\n",
        "  print(\"about to import \" + q + \" from file \" + railMappings[q][\"@fileName\"])\n",
        "  df = pd.read_csv(railMappings[q][\"@fileName\"])\n",
        "  result = insert_data(session, cypher_import[q], df, batch_size = 300) \n",
        "  print(result)\n",
        "  \n",
        "  \n",
        "  #load csv from 'file:///artists.csv' AS row\n",
        "  #LOAD CSV from railMappings[q][\"@fileName\"] AS row\n",
        "  \n",
        "  \n",
        "  #print(\"How do you create a data_frame from a .csv file?\")\n",
        "  #insert_data(session, cypher_import[q], data_frame, batch_size=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Closing session and driver\")\n",
        "session.close()\n",
        "driver.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2b4j854JkAO"
      },
      "outputs": [],
      "source": [
        "print(\"Connect to a neo4j sandbox\")\n",
        "driver = GraphDatabase.driver(\n",
        "  \"bolt://3.84.57.61:7687\",\n",
        "  auth=basic_auth(\"neo4j\", \"south-kettles-harmony\"))\n",
        "\n",
        "session = driver.session(database=\"neo4j\")\n",
        "\n",
        "#cypher_import , mapping_defs = getLoadersFromOnto(onto,\"turtle\",railMappings)\n",
        "\n",
        "for q in cypher_import.keys():\n",
        "  print(\"about to import \" + q + \" from file \" + railMappings[q][\"@fileName\"])\n",
        "  df = pd.read_csv(railMappings[q][\"@fileName\"])\n",
        "  result = insert_data(session, cypher_import[q], df, batch_size = 300) \n",
        "  print(result)\n",
        "\n",
        "for md in mapping_defs:\n",
        "  session.run(md)\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPa90V5qw4Hy/CLydkkxIwD",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Ontology Driven KG creation",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
